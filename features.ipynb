{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8546, 143)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = './mof_features'\n",
    "df_fea = pd.read_csv(os.path.join(folder_path, 'Features_RACS.csv'), index_col=0)\n",
    "# duplicate_index = df_fea.index.duplicated()\n",
    "# df_no_duplicates = df_fea[~duplicate_index]\n",
    "# df_no_duplicates.to_csv(os.path.join(folder_path, 'matminer_racs_all.csv'))\n",
    "df_fea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = './features'\n",
    "\n",
    "# # Get all feature csv in the folder\n",
    "# all_files = os.listdir(folder_path)\n",
    "# filtered_files = [file for file in all_files if file.startswith('matminer_racs_')]\n",
    "# fea_lst = []\n",
    "# for file in filtered_files:\n",
    "#     df_fea = pd.read_csv(os.path.join(folder_path, file), index_col=0)\n",
    "#     fea_lst.append(df_fea)\n",
    "# df_all = pd.concat(fea_lst)\n",
    "\n",
    "# df_all.to_csv(os.path.join(folder_path, 'matminer_racs_all.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/yll6162/miniconda3/envs/mof/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_182941/1083385359.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_fea['sample'] = df_fea['MOF Name'] + '.cif'\n"
     ]
    }
   ],
   "source": [
    "tl = False\n",
    "folder_path = './mof_features'\n",
    "df_fea = pd.read_csv(os.path.join(folder_path, 'Features_RACS.csv'), index_col=0)\n",
    "\n",
    "# df_fea.values\n",
    "label_encoder = LabelEncoder()\n",
    "# if 'compound possible' in df_fea.columns:\n",
    "#     df_fea['compound possible'] = df_fea['compound possible'].replace({'False': 0, 'True': 1, False: 0, True: 1, '0.0': 0}).astype(float)\n",
    "# for str_label in ['HOMO_character', 'HOMO_element', 'LUMO_character', 'LUMO_element']:\n",
    "#     if str_label in df_fea.columns:\n",
    "#         df_fea[str_label] = label_encoder.fit_transform(df_fea[str_label].astype(str))\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_feature = encoder.fit_transform(df_fea[['Metal']])\n",
    "df_fea = df_fea.reset_index(drop=True)\n",
    "df_fea = pd.concat([df_fea, pd.DataFrame(encoded_feature, columns=encoder.get_feature_names_out(['Metal']))], axis=1)\n",
    "df_fea = df_fea.drop(columns = ['Metal'])\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "feature_cols = df_fea.columns[2:]\n",
    "df_fea[feature_cols] = imputer.fit_transform(df_fea[feature_cols].values)\n",
    "df_fea['sample'] = df_fea['MOF Name'] + '.cif'\n",
    "df_fea.to_csv(os.path.join(folder_path, 'racs_all_clean.csv'))\n",
    "# df_fea[['HOMO_character', 'HOMO_element', 'LUMO_character', 'LUMO_element']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine with ALIGNN Embeddings (Optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = True\n",
    "run = 'mof_form_e_embed'\n",
    "embed_filepath = f\"/scratch/yll6162/ALIGNNTL/examples/{run}/x+y+z/data0.csv\"\n",
    "df_embed = pd.read_csv(embed_filepath)\n",
    "df_embed = df_embed.drop_duplicates(subset = ['id'])\n",
    "df_fea_all = df_fea.merge(df_embed, how='left', left_on = \"MOF Name\", right_on = \"id\").drop(columns = ['oxo','id'])\n",
    "df_fea = df_fea_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "racs_col = [col for col in df_fea.columns if col.startswith(\"racs_\")]\n",
    "embed_cols = [str(i) for i in range(768)]\n",
    "scaler_A = StandardScaler()\n",
    "df_fea[racs_col] = scaler_A.fit_transform(df_fea[racs_col].values)\n",
    "# if embed_cols:\n",
    "#     scaler_B = StandardScaler()\n",
    "#     df_fea[embed_cols] = scaler_B.fit_transform(df_fea[embed_cols].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182941/760257893.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_sample['ids'] = df_sample['sample'] + '_' + df_sample['Site'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# prop = 'Oxo Formation Energy'\n",
    "prop = 'Hydrogen Affinity Energy'\n",
    "output_dir = './data/'\n",
    "df_qmof = pd.read_csv(\"./labels/qmofruns_2_suffled.csv\", index_col = 0)\n",
    "df_qmof['sample'] = df_qmof.MOF + '.cif'\n",
    "\n",
    "df_qmof['prop'] = df_qmof[prop]\n",
    "df_qmof = df_qmof[['sample', 'Site', prop]]\n",
    "\n",
    "df_fea['sample'] = df_fea['MOF Name'] + '.cif'\n",
    "\n",
    "df_sample = df_qmof.merge(df_fea, how='left', left_on=['sample', 'Site'], right_on = ['sample','Metal_index'])\n",
    "df_sample['ids'] = df_sample['sample'] + '_' + df_sample['Site'].astype(str)\n",
    "df_sample = df_sample.drop(columns = ['sample', 'Site', 'MOF Name', 'Metal_index'])\n",
    "df_sample = df_sample.assign(**{prop: df_sample.pop(prop)})\n",
    "df_sample = df_sample.assign(**{'ids': df_sample.pop('ids')})\n",
    "if tl:\n",
    "    df_sample.to_csv(os.path.join(output_dir, f\"full_data_{run}_{prop}.csv\"), index=False)\n",
    "else:\n",
    "    df_sample.to_csv(os.path.join(output_dir, f\"full_data_racs_{prop}.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
